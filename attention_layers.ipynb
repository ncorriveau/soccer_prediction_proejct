{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMs6JVYo6IBNuwTaUqNbjN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ncorriveau/transformers_for_prediction/blob/main/attention_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ziA0RLzcuFEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPtMTp3TXrBp",
        "outputId": "0d7e96d5-5a32-4df9-b1cf-15dc4bf7a8a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4pQ362TX_w4",
        "outputId": "b5e00096-8b3c-4351-f734-2076af26eaa2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "EIlpu7lkXzJF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load our numpy tensors to load into keras \n",
        "features_path = '/content/drive/MyDrive/Data Mining/features.npy'\n",
        "labels_path = '/content/drive/MyDrive/Data Mining/labels.npy'\n",
        "features = np.load(features_path)\n",
        "labels = np.load(labels_path)"
      ],
      "metadata": {
        "id": "0chvsS9zYQ5R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features.shape)\n",
        "print(labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyzQOW2gYpcE",
        "outputId": "f7b133b7-62d1-4b9b-8ae5-43b8aeff9e6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21361, 22, 66)\n",
            "(21361, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the numerical features which are locatead in cols 0-35\n",
        "features_num = features[:,:,:35]\n",
        "print(features_num.shape)\n",
        "\n",
        "features_num[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqWIojDFZeTE",
        "outputId": "d2a75b8e-f5b8-4593-8a6c-0719503b7c26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21361, 22, 35)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([58., 67., 25., 25., 25., 25., 10., 25., 16., 12., 46., 35., 45.,\n",
              "       41., 41., 57., 72., 25., 56., 40., 73., 25., 57., 40., 33., 50.,\n",
              "       48., 25., 25., 35., 63., 51., 46., 53., 68.])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(features_num,axis=(0,1))\n",
        "print(f\"shape of mean vector = {mean.shape}\")\n",
        "\n",
        "std = np.std(features_num,axis=(0,1))\n",
        "print(f\"shape of std vector = {std.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWKPDTLBb_xe",
        "outputId": "a8cc9352-0303-495c-a8be-7b25d02854db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of mean vector = (35,)\n",
            "shape of std vector = (35,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_num = (features_num - mean) / std\n",
        "print(features_num.shape)\n",
        "print(features_num[0][0])\n",
        "\n",
        "features[:,:,:35] = features_num \n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Uiykt1Le0Vb",
        "outputId": "9f8406aa-ce5c-42f3-c3db-ed7b54374c3a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21361, 22, 35)\n",
            "[-2.13402071 -1.37252412 -1.77469422 -1.23838184 -1.99655923 -2.73920252\n",
            " -2.04805005 -1.86919281 -1.97499507 -2.01346997 -0.99274355 -1.92213186\n",
            " -1.8076617  -2.24156397 -2.00765514 -1.48199584  0.46714265 -2.30508048\n",
            " -1.20626801 -2.30813745  0.28191452 -1.50510393 -0.48443304 -0.86434178\n",
            " -1.24425375 -0.70543806 -0.52144225 -1.16782289 -1.33347824 -0.76945225\n",
            "  2.46779935  1.85987951  0.88080786  1.93442016  2.57236977]\n",
            "(21361, 22, 66)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = np.round(features.shape[0]*0.7)\n",
        "val_num = np.round(features.shape[0]*0.15)\n",
        "test_num = np.round(features.shape[0]*0.15)\n",
        "train_index = int(train_num)\n",
        "val_index = int(train_num+val_num)\n",
        "test_index = int(val_index+test_num)\n",
        "\n",
        "print(f\"Training sample size = {train_num}, Validation set size = {val_num}, Test set size = {test_num}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj0zzDEXYudr",
        "outputId": "647e2607-9ca8-4cec-9dac-946e06b12631"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sample size = 14953.0, Validation set size = 3204.0, Test set size = 3204.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are working with time series data, i.e. each in the match dataset and thus our numpy array is in ordered by match date. "
      ],
      "metadata": {
        "id": "q3pALgFpl9k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = features[:train_index,:,:]\n",
        "train_labels = labels[:train_index,:]\n",
        "\n",
        "val_features = features[train_index:val_index,:,:]\n",
        "val_labels = labels[train_index:val_index,:]\n",
        "\n",
        "test_features = features[val_index:,:,:]\n",
        "test_labels = labels[val_index:,:]"
      ],
      "metadata": {
        "id": "-195LDKtblLi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_features.shape, test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naQ1hbtbhBb2",
        "outputId": "852c573e-7336-457a-b767-381494e28a48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3204, 22, 66) (3204, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#turn data into dataset objects \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_features, val_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_features, test_labels))"
      ],
      "metadata": {
        "id": "gXwXSMFMkk3e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Naive Implementations\n",
        "\n",
        "We get a baseline model by implementing a naive dense model that just flattens all weights, and then we try a first stab at a transformer with 12 layers that self encodes all of the data and has a MLP classifier as a head\n",
        "\n"
      ],
      "metadata": {
        "id": "SGwIdSy3uLru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, now we finally have data that's ready to go in tf. let's run it through a very simple network and see what we get. "
      ],
      "metadata": {
        "id": "grU63LpDlrhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_dataset.shuffle(100).batch(32)\n",
        "val_ds = val_dataset.batch(32)\n",
        "test_ds = test_dataset.batch(32)"
      ],
      "metadata": {
        "id": "2NtVi8ejtY13"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "simple_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(3,activation=\"softmax\",)\n",
        "])\n",
        "\n",
        "simple_model.compile(optimizer='adam',\n",
        "              loss=['categorical_crossentropy'] ,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "simple_model.build(input_shape=(None,22,66))\n",
        "simple_model.summary()"
      ],
      "metadata": {
        "id": "4j0wWwaJlHcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0801c7b8-2ece-4f25-a7ab-4c5b65f66e82"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 1452)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 4359      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,359\n",
            "Trainable params: 4,359\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.fit(train_ds, epochs=10)"
      ],
      "metadata": {
        "id": "bSYCK2fdrU6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cce8404-eda6-4fed-a013-03591083a300"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "468/468 [==============================] - 2s 2ms/step - loss: 1.0734 - accuracy: 0.4757\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 1.0228 - accuracy: 0.5052\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 1.0048 - accuracy: 0.5166\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 1s 2ms/step - loss: 0.9963 - accuracy: 0.5190\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 1s 2ms/step - loss: 0.9920 - accuracy: 0.5234\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.9820 - accuracy: 0.5331\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.9866 - accuracy: 0.5315\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 1s 3ms/step - loss: 0.9820 - accuracy: 0.5323\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 1s 1ms/step - loss: 0.9797 - accuracy: 0.5358\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 1s 1ms/step - loss: 0.9688 - accuracy: 0.5396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3be832e1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test acc: {simple_model.evaluate(test_ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK5VsWC6tcO8",
        "outputId": "988baf7e-1a26-494c-980f-3278b5b87b5a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101/101 [==============================] - 0s 1ms/step - loss: 1.0891 - accuracy: 0.4844\n",
            "Test acc: [1.0891447067260742, 0.48439452052116394]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer Implementation\n",
        "Here we are going to follow some more granular techniques to create a couple sub modules from Keras Layers to implement an architecture closely related to [Vision Transformers ](https://https://github.com/keras-team/keras-io/blob/master/examples/vision/image_classification_with_vision_transformer.py)\n",
        "\n",
        "So far we ran our data, (which is a (sample x 22 players x 66 features) vector through both a simple flatten --> MLP layer, resulting in ~45% test accuracy, and a naive transformer implementation where we put it through a linear projection layer, 12 layers of 4 head multihead self attention, global max pooling and then a classification layer on top of that. \n",
        "\n",
        "We will be changing our implementation to make it more customizable and now try two different approaches: \n",
        "1.) Separate the data to learn a representation of each team through self attention (i.e. two (11xfeature length) inputs) \n",
        "2.) Same approach as before \n",
        "\n",
        "In both cases we will increase numper of MLP layers, and also flatten the output of the self attention blocks into (batch x (256*11)) vectors as inputs into the MLP. \n",
        "\n",
        "We will also take the position indicator in the feature vector (second to last position), and embed it and add it to back to the feature vector before putting it through the attention block. This is the same approach taken in the Vision Transformers paper linked above. "
      ],
      "metadata": {
        "id": "YWUsC0r3ucQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Start with our full feature tensor and slice it into train, val, and test set with \n",
        "splitting of teams and then creating a separate tensor for positions in each match'''\n",
        "\n",
        "def split_tensor(features,labels, index1=0,index2=-1):\n",
        "  '''Start with our full feature tensor of shape (matches x 22 x feature_size) \n",
        "  and slice it into train, val, and test set with \n",
        "  splitting of teams and then creating a separate tensor for \n",
        "  positions in each match \n",
        "  Output will be:\n",
        "   team1 (index1:index2 x 11 x feature_size-2)\n",
        "   team2 (index1:index2 x 11 x feature_size-2)\n",
        "   team1_pos (index1:index2 x 11 x 1)\n",
        "   team2_pos (index1:index2 x 11 x 1)\n",
        "   Slice the labels tensor to be (index1:index2, 3,) '''\n",
        "  \n",
        "  features_ = features[index1:index2,:,:-2]\n",
        "  team_1 = features_[:,:11,:]\n",
        "  team_2 = features_[:,11:,:]\n",
        "  team_1_pos = features[index1:index2,:11,-2:-1]\n",
        "  team_2_pos = features[index1:index2,11:,-2:-1]\n",
        "  labels_ = labels[index1:index2,:]\n",
        "\n",
        "  return team_1, team_2, team_1_pos, team_2_pos, labels_\n",
        "\n",
        "\n",
        "train_team_1, train_team_2, train_team_1_pos, train_team_2_pos,\\\n",
        " train_labels = split_tensor(features, labels, index2=train_index)\n",
        "\n",
        "val_team_1, val_team_2, val_team_1_pos, val_team_2_pos,\\\n",
        " val_labels = split_tensor(features,labels,index1=train_index,index2=val_index)\n",
        "\n",
        "\n",
        "test_team_1, test_team_2, test_team_1_pos, test_team_2_pos,\\\n",
        "test_labels = split_tensor(features, labels, index1=val_index)"
      ],
      "metadata": {
        "id": "QsiBLfDS0e1z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_index, val_index, test_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyu1IFU0Qxkm",
        "outputId": "cf3642a5-9aa4-46d8-c1dc-1faeb19aa94d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14953 18157 21361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Team 1 Shape = {train_team_1.shape}, \\nTeam 2 Shape = {train_team_2.shape}\\\n",
        "        \\nTeam 1 Positions = {train_team_1_pos.shape}\")\n",
        "\n",
        "print(f\"Team 1 Shape = {val_team_1.shape}, \\nTeam 2 Shape = {val_team_2.shape}\\\n",
        "        \\nTeam 1 Positions = {val_team_1_pos.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Team 1 Shape = {test_team_1.shape}, \\nTeam 2 Shape = {test_team_2.shape}\\\n",
        "        \\nTeam 1 Positions = {test_team_1_pos.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt2VZWB6GOVW",
        "outputId": "bfce8693-7d84-4e5e-f1ff-f7d5bd274133"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Team 1 Shape = (14953, 11, 64), \n",
            "Team 2 Shape = (14953, 11, 64)        \n",
            "Team 1 Positions = (14953, 11, 1)\n",
            "Team 1 Shape = (3204, 11, 64), \n",
            "Team 2 Shape = (3204, 11, 64)        \n",
            "Team 1 Positions = (3204, 11, 1)\n",
            "Team 1 Shape = (3203, 11, 64), \n",
            "Team 2 Shape = (3203, 11, 64)        \n",
            "Team 1 Positions = (3203, 11, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\":train_team_1,\"input_2\":train_team_2}, train_labels))\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\":val_team_1,\"input_2\":val_team_2}, val_labels))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(({\"input_1\":test_team_1,\"input_2\":test_team_2}, test_labels))\n"
      ],
      "metadata": {
        "id": "r8eeso6pF4hE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "input_shape = (11,64)\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "num_players = 11\n",
        "projection_dim = 256\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "] \n",
        "\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n"
      ],
      "metadata": {
        "id": "YVoR-R9sxYT7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Implement MLP layers'''\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Encoder(layers.Layer):\n",
        "  '''Takes the original input layer, projects it and then adds a positional encoding layer to it'''\n",
        "  def __init__(self, num_players, projection_dim):\n",
        "      super().__init__()\n",
        "      self.num_players = num_players\n",
        "      self.projection = layers.Dense(units=projection_dim)\n",
        "      self.position_embedding = layers.Embedding(\n",
        "          input_dim=num_players, output_dim=projection_dim\n",
        "      )\n",
        "\n",
        "  def call(self, players):\n",
        "      positions = tf.range(start=0, limit=self.num_players, delta=1)\n",
        "      encoded = self.projection(players) + self.position_embedding(positions)\n",
        "      return encoded\n",
        "  "
      ],
      "metadata": {
        "id": "3XT6J2z5TTg8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_block(team):\n",
        "    '''Input a particular team as a set of (batch_size, 11, feature size) vectors,\n",
        "     and returns output of transformer block that will be used in classification downstream'''\n",
        "    encoded_players = Encoder(num_players, projection_dim)(team)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_players)\n",
        "        # Create a multi-head attention layer.\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "        )(x1, x1)\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_players])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x4 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "       \n",
        "        # Skip connection 2.\n",
        "        encoded_players1= layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_players)\n",
        "\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    return representation\n",
        "    "
      ],
      "metadata": {
        "id": "1wW_3ul3VfeQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input1 = layers.Input(shape =input_shape)\n",
        "input2 = layers.Input(shape=input_shape)\n",
        "\n",
        "representation1 = transformer_block(input1)\n",
        "representation2 = transformer_block(input2)\n",
        "\n",
        "representation = layers.Concatenate()([representation1,representation2])\n",
        "features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "# Classify outputs.\n",
        "logits = layers.Dense(num_classes)(features)\n",
        "# Create the Keras model.\n",
        "model = keras.Model(inputs=[input1, input2], outputs=logits)"
      ],
      "metadata": {
        "id": "04EtgKpLe__s"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/content/drive/MyDrive/Data Mining/\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x = [train_team_1, train_team_2],\n",
        "        y = train_labels,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        validation_data = ([val_team_1,val_team_2],val_labels),\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    # model.load_weights(checkpoint_filepath)\n",
        "    # _, accuracy, top_5_accuracy = model.evaluate([test_team_1, test_team_2],test_labels)\n",
        "    # print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    # print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "X4nBRNQ_XvnX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = run_experiment(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA1lMgV-hN76",
        "outputId": "20542e85-3f82-45f2-d835-349f02ae7c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "468/468 [==============================] - 59s 124ms/step - loss: 1.3873 - accuracy: 0.4519 - val_loss: 1.0426 - val_accuracy: 0.5006\n",
            "Epoch 2/100\n",
            "468/468 [==============================] - 58s 123ms/step - loss: 1.0366 - accuracy: 0.4878 - val_loss: 0.9942 - val_accuracy: 0.5175\n",
            "Epoch 3/100\n",
            "468/468 [==============================] - 56s 120ms/step - loss: 1.0238 - accuracy: 0.5031 - val_loss: 1.0151 - val_accuracy: 0.5209\n",
            "Epoch 4/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 1.0191 - accuracy: 0.4981 - val_loss: 1.0036 - val_accuracy: 0.5181\n",
            "Epoch 5/100\n",
            "468/468 [==============================] - 57s 122ms/step - loss: 1.0107 - accuracy: 0.5092 - val_loss: 0.9924 - val_accuracy: 0.5172\n",
            "Epoch 6/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 1.0117 - accuracy: 0.5067 - val_loss: 1.0000 - val_accuracy: 0.5262\n",
            "Epoch 7/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 1.0086 - accuracy: 0.5111 - val_loss: 0.9777 - val_accuracy: 0.5306\n",
            "Epoch 8/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 1.0057 - accuracy: 0.5097 - val_loss: 0.9777 - val_accuracy: 0.5212\n",
            "Epoch 9/100\n",
            "468/468 [==============================] - 56s 120ms/step - loss: 0.9963 - accuracy: 0.5160 - val_loss: 0.9767 - val_accuracy: 0.5334\n",
            "Epoch 10/100\n",
            "468/468 [==============================] - 56s 120ms/step - loss: 1.0012 - accuracy: 0.5113 - val_loss: 1.0023 - val_accuracy: 0.4800\n",
            "Epoch 11/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 0.9896 - accuracy: 0.5218 - val_loss: 0.9816 - val_accuracy: 0.5250\n",
            "Epoch 12/100\n",
            "468/468 [==============================] - 58s 123ms/step - loss: 0.9877 - accuracy: 0.5229 - val_loss: 1.0048 - val_accuracy: 0.5162\n",
            "Epoch 13/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.9827 - accuracy: 0.5220 - val_loss: 1.0153 - val_accuracy: 0.5044\n",
            "Epoch 14/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 0.9776 - accuracy: 0.5185 - val_loss: 1.0186 - val_accuracy: 0.4850\n",
            "Epoch 15/100\n",
            "468/468 [==============================] - 58s 125ms/step - loss: 0.9707 - accuracy: 0.5271 - val_loss: 0.9980 - val_accuracy: 0.5337\n",
            "Epoch 16/100\n",
            "468/468 [==============================] - 56s 120ms/step - loss: 0.9604 - accuracy: 0.5378 - val_loss: 1.0043 - val_accuracy: 0.5281\n",
            "Epoch 17/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.9516 - accuracy: 0.5342 - val_loss: 1.0206 - val_accuracy: 0.5200\n",
            "Epoch 18/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 0.9442 - accuracy: 0.5428 - val_loss: 1.0523 - val_accuracy: 0.4966\n",
            "Epoch 19/100\n",
            "468/468 [==============================] - 58s 123ms/step - loss: 0.9246 - accuracy: 0.5516 - val_loss: 1.0124 - val_accuracy: 0.5218\n",
            "Epoch 20/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 0.9044 - accuracy: 0.5624 - val_loss: 1.0345 - val_accuracy: 0.5200\n",
            "Epoch 21/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.8789 - accuracy: 0.5817 - val_loss: 1.0852 - val_accuracy: 0.5247\n",
            "Epoch 22/100\n",
            "468/468 [==============================] - 56s 121ms/step - loss: 0.8472 - accuracy: 0.5920 - val_loss: 1.1527 - val_accuracy: 0.4894\n",
            "Epoch 23/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.8160 - accuracy: 0.6174 - val_loss: 1.1460 - val_accuracy: 0.4744\n",
            "Epoch 24/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.7804 - accuracy: 0.6400 - val_loss: 1.2221 - val_accuracy: 0.4822\n",
            "Epoch 25/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.7291 - accuracy: 0.6743 - val_loss: 1.2911 - val_accuracy: 0.4822\n",
            "Epoch 26/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.6793 - accuracy: 0.6955 - val_loss: 1.2697 - val_accuracy: 0.4660\n",
            "Epoch 27/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.6359 - accuracy: 0.7223 - val_loss: 1.3013 - val_accuracy: 0.4638\n",
            "Epoch 28/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.5920 - accuracy: 0.7464 - val_loss: 1.3617 - val_accuracy: 0.4785\n",
            "Epoch 29/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.5468 - accuracy: 0.7733 - val_loss: 1.5034 - val_accuracy: 0.4576\n",
            "Epoch 30/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.4907 - accuracy: 0.7966 - val_loss: 1.4433 - val_accuracy: 0.4323\n",
            "Epoch 31/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.4752 - accuracy: 0.8063 - val_loss: 1.4579 - val_accuracy: 0.4760\n",
            "Epoch 32/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.4400 - accuracy: 0.8268 - val_loss: 1.3691 - val_accuracy: 0.4345\n",
            "Epoch 33/100\n",
            "468/468 [==============================] - 56s 121ms/step - loss: 0.3980 - accuracy: 0.8454 - val_loss: 1.5191 - val_accuracy: 0.4504\n",
            "Epoch 34/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.3796 - accuracy: 0.8523 - val_loss: 1.4286 - val_accuracy: 0.4576\n",
            "Epoch 35/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.3503 - accuracy: 0.8654 - val_loss: 1.6599 - val_accuracy: 0.4744\n",
            "Epoch 36/100\n",
            "468/468 [==============================] - 57s 121ms/step - loss: 0.3400 - accuracy: 0.8716 - val_loss: 1.4677 - val_accuracy: 0.4376\n",
            "Epoch 37/100\n",
            "468/468 [==============================] - 56s 119ms/step - loss: 0.3258 - accuracy: 0.8785 - val_loss: 1.6148 - val_accuracy: 0.4613\n",
            "Epoch 38/100\n",
            "468/468 [==============================] - 56s 120ms/step - loss: 0.3148 - accuracy: 0.8792 - val_loss: 1.5720 - val_accuracy: 0.4557\n",
            "Epoch 39/100\n",
            "468/468 [==============================] - 61s 130ms/step - loss: 0.3014 - accuracy: 0.8857 - val_loss: 1.6200 - val_accuracy: 0.4522\n",
            "Epoch 40/100\n",
            "468/468 [==============================] - 55s 118ms/step - loss: 0.2941 - accuracy: 0.8897 - val_loss: 1.5804 - val_accuracy: 0.4635\n",
            "Epoch 41/100\n",
            "212/468 [============>.................] - ETA: 30s - loss: 0.2628 - accuracy: 0.9021"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PRp8IulhhnPf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}